{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST (Modified National Institute of Standards and Technology) dataset consists of images of handwritten digits that is used for training and testing image processing systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a multiclass classification problem in which the goal is to predict a single discrete label (0,1,2,3,4,5,6,7,8,9)\n",
    "\n",
    "This notebook is used to generate a predictive model for the production system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "import numpy as np  # linear algebra\n",
    "from skimage import io, transform, util\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist  # mnist dataset\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the network is a layer of size 10 with a probability distribution over the 10 different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation=\"relu\", input_shape=(28 * 28,)))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen loss function is categorical_crossentropy because is a multiclass classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_prepared = train_images.reshape((60000, 28 * 28))\n",
    "train_images_prepared = train_images_prepared.astype(\"float32\") / 255\n",
    "\n",
    "test_images_prepared = test_images.reshape((10000, 28 * 28))\n",
    "test_images_prepared = test_images_prepared.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a validation set of 6000 samples from 60000 training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_val = train_images_prepared[:6000]\n",
    "train_images_partial = train_images_prepared[6000:]\n",
    "\n",
    "train_labels_val = train_labels_one_hot[:6000]\n",
    "train_labels_partial = train_labels_one_hot[6000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model for 10 epochs or passes over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 21:18:56.862940: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 169344000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.4630 - val_accuracy: 0.9535 - val_loss: 0.1597\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9642 - loss: 0.1230 - val_accuracy: 0.9687 - val_loss: 0.1054\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9777 - loss: 0.0754 - val_accuracy: 0.9762 - val_loss: 0.0829\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0531 - val_accuracy: 0.9810 - val_loss: 0.0675\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0384 - val_accuracy: 0.9807 - val_loss: 0.0637\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0285 - val_accuracy: 0.9803 - val_loss: 0.0656\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0220 - val_accuracy: 0.9805 - val_loss: 0.0666\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0152 - val_accuracy: 0.9813 - val_loss: 0.0594\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0121 - val_accuracy: 0.9783 - val_loss: 0.0678\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0086 - val_accuracy: 0.9822 - val_loss: 0.0673\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_images_partial,\n",
    "    train_labels_partial,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=(train_images_val, train_labels_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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